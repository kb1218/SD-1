import requests
from bs4 import BeautifulSoup
import csv

def scrape_ecommerce_website(url):
    headers = {'User-Agent': 'Mozilla/5.0'}
    response = requests.get(url, headers=headers)
    
    if response.status_code != 200:
        print("Failed to retrieve the webpage")
        return
    
    soup = BeautifulSoup(response.text, 'html.parser')
    products = []
    
    for item in soup.select('.product-item'):  # Adjust selector as per the website structure
        name = item.select_one('.product-title').get_text(strip=True) if item.select_one('.product-title') else 'N/A'
        price = item.select_one('.product-price').get_text(strip=True) if item.select_one('.product-price') else 'N/A'
        link = item.select_one('a')['href'] if item.select_one('a') else 'N/A'
        
        products.append([name, price, link])
    
    save_to_csv(products)

def save_to_csv(products, filename="products.csv"):
    with open(filename, 'w', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        writer.writerow(["Product Name", "Price", "URL"])
        writer.writerows(products)
    print(f"Data saved to {filename}")

if __name__ == "__main__":
    url = input("Enter the e-commerce website URL: ")
    scrape_ecommerce_website(url)
